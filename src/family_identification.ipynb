{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "#from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from numpy import nan\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "CLASS_NUM = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = IMG_WIDTH, IMG_HEIGHT\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    shape_ord = (3, img_rows, img_cols)\n",
    "else:  # channel_last\n",
    "    shape_ord = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import vgg16\n",
    "from keras.layers import Input\n",
    "\n",
    "# build the VGG16 network with ImageNet weights\n",
    "vgg16 = vgg16.VGG16(weights='imagenet', include_top=False, input_tensor=Input((224, 224, 3)),classes=CLASS_NUM)\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in vgg16.layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten(input_shape=vgg16.output.shape)(vgg16.output)\n",
    "x = Dense(4096, activation='relu', name='ft_fc1')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2048, activation='relu', name='ft_fc2')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "predictions = Dense(CLASS_NUM, activation = 'softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "model = Model(inputs=vgg16.input, outputs=predictions)\n",
    "\n",
    "#compile the model\n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2615 images belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../data/train_f2',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32, #changed from 1, change back if needed\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 872 images belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        '../data/validation_f2',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 388 images belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        '../data/test_f2',\n",
    "        target_size=(224,224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "82/82 [==============================] - 95s 1s/step - loss: 3.3782 - acc: 0.1056 - val_loss: 2.9659 - val_acc: 0.2294\n",
      "Epoch 2/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 2.9437 - acc: 0.1637 - val_loss: 2.5064 - val_acc: 0.2477\n",
      "Epoch 3/40\n",
      "82/82 [==============================] - 85s 1s/step - loss: 2.7324 - acc: 0.2203 - val_loss: 2.3113 - val_acc: 0.2901\n",
      "Epoch 4/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 2.6238 - acc: 0.2397 - val_loss: 2.1691 - val_acc: 0.3417\n",
      "Epoch 5/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 2.4943 - acc: 0.2577 - val_loss: 2.0781 - val_acc: 0.3486\n",
      "Epoch 6/40\n",
      "82/82 [==============================] - 87s 1s/step - loss: 2.4221 - acc: 0.2709 - val_loss: 2.0833 - val_acc: 0.3532\n",
      "Epoch 7/40\n",
      "82/82 [==============================] - 87s 1s/step - loss: 2.2823 - acc: 0.2979 - val_loss: 2.0572 - val_acc: 0.3658\n",
      "Epoch 8/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 2.2494 - acc: 0.3039 - val_loss: 2.0440 - val_acc: 0.3486\n",
      "Epoch 9/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 2.2431 - acc: 0.3028 - val_loss: 2.0054 - val_acc: 0.3750\n",
      "Epoch 10/40\n",
      "82/82 [==============================] - 79s 961ms/step - loss: 2.1673 - acc: 0.3177 - val_loss: 1.9982 - val_acc: 0.3681\n",
      "Epoch 11/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 2.1050 - acc: 0.3488 - val_loss: 1.9694 - val_acc: 0.3922\n",
      "Epoch 12/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 2.0717 - acc: 0.3548 - val_loss: 1.9160 - val_acc: 0.3888\n",
      "Epoch 13/40\n",
      "82/82 [==============================] - 79s 961ms/step - loss: 2.0517 - acc: 0.3540 - val_loss: 1.9174 - val_acc: 0.3991\n",
      "Epoch 14/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 1.9620 - acc: 0.3798 - val_loss: 1.8448 - val_acc: 0.4300\n",
      "Epoch 15/40\n",
      "82/82 [==============================] - 81s 983ms/step - loss: 1.9306 - acc: 0.3924 - val_loss: 1.8419 - val_acc: 0.4278\n",
      "Epoch 16/40\n",
      "82/82 [==============================] - 79s 961ms/step - loss: 1.8833 - acc: 0.4070 - val_loss: 1.7858 - val_acc: 0.4495\n",
      "Epoch 17/40\n",
      "82/82 [==============================] - 85s 1s/step - loss: 1.8983 - acc: 0.4064 - val_loss: 1.8078 - val_acc: 0.4472\n",
      "Epoch 18/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 1.8492 - acc: 0.4092 - val_loss: 1.7876 - val_acc: 0.4427\n",
      "Epoch 19/40\n",
      "82/82 [==============================] - 85s 1s/step - loss: 1.8053 - acc: 0.4268 - val_loss: 1.7955 - val_acc: 0.4381\n",
      "Epoch 20/40\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.7836 - acc: 0.4258 - val_loss: 1.7305 - val_acc: 0.4599\n",
      "Epoch 21/40\n",
      "82/82 [==============================] - 80s 977ms/step - loss: 1.7739 - acc: 0.4495 - val_loss: 1.7153 - val_acc: 0.4667\n",
      "Epoch 22/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 1.7242 - acc: 0.4446 - val_loss: 1.7627 - val_acc: 0.4427\n",
      "Epoch 23/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 1.6713 - acc: 0.4660 - val_loss: 1.6851 - val_acc: 0.4667\n",
      "Epoch 24/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 1.6521 - acc: 0.4775 - val_loss: 1.6529 - val_acc: 0.4736\n",
      "Epoch 25/40\n",
      "82/82 [==============================] - 79s 967ms/step - loss: 1.6488 - acc: 0.4690 - val_loss: 1.7181 - val_acc: 0.4484\n",
      "Epoch 26/40\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.6423 - acc: 0.4878 - val_loss: 1.6276 - val_acc: 0.4839\n",
      "Epoch 27/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 1.6003 - acc: 0.4930 - val_loss: 1.6505 - val_acc: 0.4908\n",
      "Epoch 28/40\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.5806 - acc: 0.5036 - val_loss: 1.5957 - val_acc: 0.4828\n",
      "Epoch 29/40\n",
      "82/82 [==============================] - 85s 1s/step - loss: 1.5463 - acc: 0.5093 - val_loss: 1.6159 - val_acc: 0.4954\n",
      "Epoch 30/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 1.5290 - acc: 0.5134 - val_loss: 1.5867 - val_acc: 0.4851\n",
      "Epoch 31/40\n",
      "82/82 [==============================] - 79s 967ms/step - loss: 1.5163 - acc: 0.5162 - val_loss: 1.6221 - val_acc: 0.4828\n",
      "Epoch 32/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 1.4853 - acc: 0.5256 - val_loss: 1.5512 - val_acc: 0.4897\n",
      "Epoch 33/40\n",
      "82/82 [==============================] - 79s 962ms/step - loss: 1.4705 - acc: 0.5270 - val_loss: 1.6128 - val_acc: 0.4851\n",
      "Epoch 34/40\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.4519 - acc: 0.5209 - val_loss: 1.6071 - val_acc: 0.4794\n",
      "Epoch 35/40\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.4254 - acc: 0.5373 - val_loss: 1.5833 - val_acc: 0.4874\n",
      "Epoch 36/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 1.4138 - acc: 0.5467 - val_loss: 1.5482 - val_acc: 0.5000\n",
      "Epoch 37/40\n",
      "82/82 [==============================] - 86s 1s/step - loss: 1.3773 - acc: 0.5630 - val_loss: 1.5228 - val_acc: 0.5046\n",
      "Epoch 38/40\n",
      "82/82 [==============================] - 85s 1s/step - loss: 1.3701 - acc: 0.5544 - val_loss: 1.5054 - val_acc: 0.5172\n",
      "Epoch 39/40\n",
      "82/82 [==============================] - 79s 962ms/step - loss: 1.3368 - acc: 0.5695 - val_loss: 1.5093 - val_acc: 0.5298\n",
      "Epoch 40/40\n",
      "82/82 [==============================] - 79s 961ms/step - loss: 1.3250 - acc: 0.5647 - val_loss: 1.5314 - val_acc: 0.5241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb4cb344160>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=82,\n",
    "        epochs=40,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=28,\n",
    "        use_multiprocessing=True)\n",
    "#         callbacks=[TensorBoard(log_dir='./tf_logs', histogram_freq=0, \n",
    "#                                write_graph=True, write_images=True, \n",
    "#                                embeddings_freq=10, \n",
    "#                                embeddings_layer_names=['block1_conv2', \n",
    "#                                                        'block5_conv1', \n",
    "#                                                        'ft_fc1'], \n",
    "#                                embeddings_metadata=None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5314044252448125, 0.5240825688073395]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(validation_generator,steps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "ft_fc1 (Dense)               (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "ft_fc2 (Dense)               (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 10245     \n",
      "=================================================================\n",
      "Total params: 125,888,325\n",
      "Trainable params: 111,169,541\n",
      "Non-trainable params: 14,718,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weight_f1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>picture2191.jpg</td>\n",
       "      <td>Caenidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>photo_1319939.jpg</td>\n",
       "      <td>Ephemerellidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>picture4569.jpg</td>\n",
       "      <td>Baetidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>picture2394.jpg</td>\n",
       "      <td>Ephemeridae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>photo_1397136.jpg</td>\n",
       "      <td>Ephemeridae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name           order\n",
       "0    picture2191.jpg        Caenidae\n",
       "1  photo_1319939.jpg  Ephemerellidae\n",
       "2    picture4569.jpg        Baetidae\n",
       "3    picture2394.jpg     Ephemeridae\n",
       "4  photo_1397136.jpg     Ephemeridae"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/test_f2/xy.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat = np_utils.to_categorical([t[i] for i in df.order], 21)\n",
    "y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "iml = []\n",
    "for f,o in zip(df.file_name,df.order):\n",
    "    i_path = '../data/test_f2/{}/{}'.format(o,f)\n",
    "    iml.append(cv2.resize(cv2.imread(i_path,1),(224,224),interpolation = cv2.INTER_AREA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = np.array(y_cat)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "\n",
    "iml = np.stack(iml)\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow(iml,y_cat,\n",
    "        batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(iml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map = {v: k for k, v in t.items()}\n",
    "y_pred = [inv_map[np.argmax(i)] for i in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [inv_map[np.argmax(i)] for i in y_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Baetidae       0.35      0.21      0.27        28\n",
      "     Baetiscidae       0.62      0.57      0.59        14\n",
      "        Caenidae       0.11      0.33      0.16         6\n",
      "       Capniidae       1.00      0.20      0.33         5\n",
      "  Chloroperlidae       0.33      0.29      0.31         7\n",
      "  Ephemerellidae       0.62      0.47      0.53        88\n",
      "     Ephemeridae       0.68      0.54      0.60        28\n",
      "   Heptageniidae       0.75      0.17      0.28        71\n",
      "  Hydropsychidae       0.08      0.09      0.09        11\n",
      "    Isonychiidae       1.00      0.33      0.50         6\n",
      "    Leptoceridae       0.33      0.38      0.35         8\n",
      "   Leptohyphidae       0.22      0.52      0.31        21\n",
      "   Limnephilidae       0.50      0.40      0.44        20\n",
      "          Midges       0.67      0.67      0.67         3\n",
      "      Nemouridae       0.24      0.82      0.37        11\n",
      "        Perlidae       0.54      0.56      0.55        25\n",
      "      Perlodidae       0.35      0.50      0.41        16\n",
      "  Philopotamidae       0.11      0.50      0.18         4\n",
      "  Pteronarcyidae       0.18      0.38      0.24         8\n",
      "  Rhyacophilidae       0.11      0.50      0.18         2\n",
      "Taeniopterygidae       0.75      0.50      0.60         6\n",
      "\n",
      "     avg / total       0.54      0.40      0.41       388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.unique(y_true, return_counts =True)\n",
    "\n",
    "y_true2 = [i if i in a[0][a[1]>15] else 'other' for i in y_true] \n",
    "y_pred2 = [i if i in a[0][a[1]>15] else 'other' for i in y_pred]\n",
    "# for i,j in zip(y_true,y_pred):\n",
    "#     if i in a[0][a[1]>15]:\n",
    "#         if j not in a[0][a[1]>15]:\n",
    "#             y_true2.append(i)\n",
    "#             y_pred2.append('other')\n",
    "#         y_true2.append(i)\n",
    "#         y_pred2.append(j)\n",
    "#     else:\n",
    "#         y_true2.append('other')\n",
    "#         y_pred2.append('other')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Baetidae', 'Ephemerellidae', 'Ephemeridae', 'Heptageniidae',\n",
       "       'Leptohyphidae', 'Limnephilidae', 'Perlidae', 'Perlodidae'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][a[1]>15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Baetidae       0.35      0.21      0.27        28\n",
      "Ephemerellidae       0.62      0.47      0.53        88\n",
      "   Ephemeridae       0.68      0.54      0.60        28\n",
      " Heptageniidae       0.75      0.17      0.28        71\n",
      " Leptohyphidae       0.22      0.52      0.31        21\n",
      " Limnephilidae       0.50      0.40      0.44        20\n",
      "      Perlidae       0.54      0.56      0.55        25\n",
      "    Perlodidae       0.35      0.50      0.41        16\n",
      "         other       0.43      0.71      0.54        91\n",
      "\n",
      "   avg / total       0.54      0.46      0.45       388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true2,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
